{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Device: cuda\n"
     ]
    }
   ],
   "source": [
    "Net = build_unet()\n",
    "# check if CUDA is available, and set it as the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"==> Device: {}\".format(device))\n",
    "\n",
    "# move model to the device\n",
    "Net.to(device)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "####### HYPERPARAMETERS #######\n",
    "\n",
    "# learning rate = 10^-4\n",
    "lr = 0.0001\n",
    "\n",
    "# patch size\n",
    "patch_size = 512\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(Net.parameters(), lr=lr)\n",
    "\n",
    "# batch size\n",
    "batch_size = 1\n",
    "\n",
    "# define number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "# keep track of the best validation loss\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# number of epochs to wait before stopping\n",
    "early_stopping = 5\n",
    "\n",
    "\n",
    "##### LOSS AND ACCURACY #######\n",
    "\n",
    "# keep track of training and validation loss\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "# keep track of training and validation accuracy\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "\n",
    "# initialize the early_stopping object\n",
    "# early_stopping = EarlyStopping(patience=early_stopping, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(img, patch_size):\n",
    "    \"\"\"\n",
    "    Crop a random patch from the image\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    x = np.random.randint(0, w - patch_size)\n",
    "    y = np.random.randint(0, h - patch_size)\n",
    "    return img[y:y + patch_size, x:x + patch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/charles/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1, 3, 512, 512])) that is different to the input size (torch.Size([1, 1, 512, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loss: 0.35670313239097595\n",
      "==> Loss: 0.3889467120170593\n",
      "==> Loss: 0.23229238390922546\n",
      "==> Loss: 0.18158477544784546\n",
      "==> Loss: 0.30527669191360474\n",
      "==> Loss: 0.25263768434524536\n",
      "==> Loss: 0.22558127343654633\n",
      "==> Loss: 0.2563576400279999\n",
      "==> Loss: 0.25788840651512146\n",
      "==> Loss: 0.20300433039665222\n",
      "==> Loss: 0.13902375102043152\n",
      "==> Loss: 0.15284602344036102\n",
      "==> Loss: 0.11452110856771469\n",
      "==> Loss: 0.10676401853561401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb Cell 4\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb#W2sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# print the loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m==> Loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(loss\u001b[39m.\u001b[39;49mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# update the training loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/charles/Desktop/DL-Seeing-In-The-Dark-Reproduction/train.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m train_loss_epoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####### SAMPLE INPUT DATA #######\n",
    "labels_dir = '/home/deeplearning/images/SonyImages/Sony/long/'\n",
    "images_dir = '/home/deeplearning/images/SonyImages/Sony/short/'\n",
    "\n",
    "images = glob.glob(images_dir + '0*.ARW')\n",
    "labels = glob.glob(labels_dir + '0*.ARW')\n",
    "\n",
    "# sort the images and labels\n",
    "images.sort()\n",
    "labels.sort()\n",
    "\n",
    "# loop over epochs with tqdm progress bar\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    # initialize the training and validation loss for this epoch\n",
    "    train_loss_epoch = 0.0\n",
    "    valid_loss_epoch = 0.0\n",
    "\n",
    "    # initialize the training and validation accuracy for this epoch\n",
    "    train_acc_epoch = 0.0\n",
    "    valid_acc_epoch = 0.0\n",
    "\n",
    "    # set the model to training mode\n",
    "    Net.train()\n",
    "\n",
    "    # loop over the training data\n",
    "    for i in range(len(images)):\n",
    "        # load the first image and label\n",
    "        image = rawpy.imread(images[i])\n",
    "        label = rawpy.imread(labels[i])\n",
    "\n",
    "        # convert the image and label to numpy arrays\n",
    "        image = image.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        label = label.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "\n",
    "        # convert the image and label to float32 data type\n",
    "        image = np.float32(image / 65535.0)\n",
    "        label = np.float32(label / 65535.0)\n",
    "\n",
    "        # crop the image and label to 512 x 512\n",
    "        image = random_crop(image, 512)\n",
    "        label = random_crop(label, 512)\n",
    "\n",
    "        # convert the image and label to tensors\n",
    "        image = torch.from_numpy(np.expand_dims(np.transpose(image, (2, 0, 1)), axis=0))\n",
    "        label = torch.from_numpy(np.expand_dims(np.transpose(label, (2, 0, 1)), axis=0))\n",
    "\n",
    "        # move the image and label to the device\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = Net(image)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print the loss\n",
    "        print(\"==> Loss: {}\".format(loss.item()))\n",
    "\n",
    "        # update the training loss\n",
    "        train_loss_epoch += loss.item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
