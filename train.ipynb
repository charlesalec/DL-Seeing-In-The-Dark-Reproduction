{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "# tensor summary import\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = build_unet()\n",
    "# check if CUDA is available, and set it as the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"==> Device: {}\".format(device))\n",
    "\n",
    "# move model to the device\n",
    "Net.to(device)\n",
    "\n",
    "# define loss function\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "####### HYPERPARAMETERS #######\n",
    "\n",
    "# learning rate = 10^-4\n",
    "lr = 0.0001\n",
    "\n",
    "# patch size\n",
    "patch_size = 512\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(Net.parameters(), lr=lr)\n",
    "\n",
    "# batch size\n",
    "batch_size = 1\n",
    "\n",
    "# define number of epochs\n",
    "n_epochs = 100\n",
    "\n",
    "# keep track of the best validation loss\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# number of epochs to wait before stopping\n",
    "early_stopping = 5\n",
    "\n",
    "\n",
    "##### LOSS  #######\n",
    "\n",
    "# keep track of training and validation loss\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "# initialize the early_stopping object\n",
    "# early_stopping = EarlyStopping(patience=early_stopping, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image, label, patch_size):\n",
    "    \"\"\"\n",
    "    Crop a random patch from the image\n",
    "    \"\"\"\n",
    "    # get the shape of the image\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # get the top left corner of the random crop\n",
    "    x = np.random.randint(0, w - patch_size)\n",
    "    y = np.random.randint(0, h - patch_size)\n",
    "\n",
    "    # crop the image\n",
    "    image = image[y:y + patch_size, x:x + patch_size]\n",
    "    label = label[y:y + patch_size, x:x + patch_size]\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the list.txt as a space separated dataframe\n",
    "df = pd.read_csv('list.csv', sep=',', header=None)\n",
    "\n",
    "# split df into input, label columns\n",
    "input_df = df.iloc[:, 0]\n",
    "label_df = df.iloc[:, 1]\n",
    "\n",
    "# create a list of tuples\n",
    "image_label_list = list(zip(input_df, label_df))\n",
    "\n",
    "# create a dataset object\n",
    "dataset = Dataset()\n",
    "\n",
    "# create a dataloader object\n",
    "dataloader = DataLoader(image_label_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('number of images in dataset: {}'.format(len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print network summary\n",
    "summary(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "cnt = 0\n",
    "\n",
    "# loop over epochs with tqdm progress bar\n",
    "t = trange(n_epochs, leave=True)\n",
    "for epoch in t:\n",
    "    # initialize the training and validation loss for this epoch\n",
    "    train_loss_epoch = 0.0\n",
    "    valid_loss_epoch = 0.0\n",
    "\n",
    "    # set the model to training mode\n",
    "    Net.train()\n",
    "\n",
    "\n",
    "    # loop over the training data\n",
    "    #### IMPORTANT ####\n",
    "    # len(images) == 3, if we are in the small size, so perhaps we can\n",
    "    # heuristically increase this in order to get better results\n",
    "    # sinze now it's just 3 images per epoch\n",
    "    for input, label in dataloader:\n",
    "        # load the first image and label\n",
    "        print(' ------------ new batch --------------')\n",
    "        print(input)\n",
    "        print(label)\n",
    "        \n",
    "        input = input[0]\n",
    "        label = label[0]\n",
    "\n",
    "\n",
    "        image = rawpy.imread(input)\n",
    "        label = rawpy.imread(label)\n",
    "\n",
    "        # convert the image and label to numpy arrays\n",
    "        image = image.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        label = label.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "\n",
    "        # convert the image and label to float32 data type\n",
    "        image = np.float32(image / 65535.0)\n",
    "        label = np.float32(label / 65535.0)\n",
    "\n",
    "                # strip input and label from paranthese\n",
    "        if cnt % 20 == 0:\n",
    "                # display the image and label\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            plt.imshow(label)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        ####### POSTPROCESSING #######\n",
    "\n",
    "        # crop the image and label to 512 x 512\n",
    "        image, label = random_crop(image, label, patch_size)\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "                # display the image and label\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            plt.imshow(label)\n",
    "            plt.show()\n",
    "\n",
    "        # convert the image and label to tensors\n",
    "        image = torch.from_numpy(np.expand_dims(np.transpose(image, (2, 0, 1)), axis=0))\n",
    "        label = torch.from_numpy(np.expand_dims(np.transpose(label, (2, 0, 1)), axis=0))\n",
    "\n",
    "        # move the image and label to the device\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = Net(image)\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "            # also display the input patch\n",
    "            plt.imshow(image[0].cpu().detach().numpy().transpose(1, 2, 0))\n",
    "            plt.imshow(output[0].cpu().detach().numpy().transpose(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print the loss\n",
    "        # print(\"==> Loss: {}\".format(loss.item()))\n",
    "        epoch_loss = loss.item()\n",
    "\n",
    "        # update the training loss\n",
    "        train_loss_epoch += loss.item()\n",
    "\n",
    "        # append loss to the list\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        cnt = cnt + 1  \n",
    "        \n",
    "\n",
    "# plot loss\n",
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
