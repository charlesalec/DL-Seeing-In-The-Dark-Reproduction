{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import *\n",
    "import functions\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "# tensor summary import\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Device: cpu\n"
     ]
    }
   ],
   "source": [
    "Net = build_unet()\n",
    "# check if CUDA is available, and set it as the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"==> Device: {}\".format(device))\n",
    "\n",
    "# move model to the device\n",
    "Net.to(device)\n",
    "\n",
    "# define loss function\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "####### HYPERPARAMETERS #######\n",
    "\n",
    "# learning rate = 10^-4\n",
    "lr = 0.0001\n",
    "\n",
    "# patch size\n",
    "patch_size = 512\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(Net.parameters(), lr=lr)\n",
    "\n",
    "# batch size\n",
    "batch_size = 10\n",
    "\n",
    "# define number of epochs\n",
    "n_epochs = 100\n",
    "\n",
    "# keep track of the best validation loss\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "# number of epochs to wait before stopping\n",
    "early_stopping = 5\n",
    "\n",
    "\n",
    "##### LOSS  #######\n",
    "\n",
    "# keep track of training and validation loss\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "# initialize the early_stopping object\n",
    "# early_stopping = EarlyStopping(patience=early_stopping, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image, label, patch_size):\n",
    "    \"\"\"\n",
    "    Crop a random patch from the image\n",
    "    \"\"\"\n",
    "    # get the shape of the image\n",
    "    h, w = image.shape[:2]\n",
    "    #h = image.shape[1]\n",
    "    #w = image.shape[2]\n",
    "\n",
    "    # get the top left corner of the random crop\n",
    "    x = np.random.randint(0, w - patch_size)\n",
    "    y = np.random.randint(0, h - patch_size)\n",
    "\n",
    "    # crop the image\n",
    "    image = image[y:y + patch_size, x:x + patch_size]\n",
    "    label = label[y * 2:y * 2 + patch_size * 2, x * 2:x * 2 + patch_size * 2]\n",
    "    # image = image[:, y:y + patch_size, x:x + patch_size, :]\n",
    "    # label = label[:, y:y + patch_size, x:x + patch_size, :]\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in dataset: 1\n"
     ]
    }
   ],
   "source": [
    "# read the list.txt as a space separated dataframe\n",
    "#df = pd.read_csv('list.csv', sep=',', header=None)\n",
    "#df = pd.read_csv('list_0.1s_shortkingdom.csv', sep=',', header=None)\n",
    "df = pd.read_csv('list_extrashortkingdom.csv', sep=',', header=None)\n",
    "\n",
    "# split df into input, label columns\n",
    "input_df = df.iloc[:, 0]\n",
    "label_df = df.iloc[:, 1]\n",
    "\n",
    "# create a list of tuples\n",
    "image_label_list = list(zip(input_df, label_df))\n",
    "\n",
    "# create a dataset object\n",
    "dataset = Dataset()\n",
    "\n",
    "# create a dataloader object\n",
    "dataloader = DataLoader(image_label_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('number of images in dataset: {}'.format(len(dataloader)))\n",
    "\n",
    "result_dir = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─encoder_block: 1-1                     --\n",
      "|    └─conv_block: 2-1                   --\n",
      "|    |    └─Conv2d: 3-1                  1,184\n",
      "|    |    └─BatchNorm2d: 3-2             64\n",
      "|    |    └─Conv2d: 3-3                  9,248\n",
      "|    |    └─BatchNorm2d: 3-4             64\n",
      "|    |    └─ReLU: 3-5                    --\n",
      "|    └─MaxPool2d: 2-2                    --\n",
      "├─encoder_block: 1-2                     --\n",
      "|    └─conv_block: 2-3                   --\n",
      "|    |    └─Conv2d: 3-6                  18,496\n",
      "|    |    └─BatchNorm2d: 3-7             128\n",
      "|    |    └─Conv2d: 3-8                  36,928\n",
      "|    |    └─BatchNorm2d: 3-9             128\n",
      "|    |    └─ReLU: 3-10                   --\n",
      "|    └─MaxPool2d: 2-4                    --\n",
      "├─encoder_block: 1-3                     --\n",
      "|    └─conv_block: 2-5                   --\n",
      "|    |    └─Conv2d: 3-11                 73,856\n",
      "|    |    └─BatchNorm2d: 3-12            256\n",
      "|    |    └─Conv2d: 3-13                 147,584\n",
      "|    |    └─BatchNorm2d: 3-14            256\n",
      "|    |    └─ReLU: 3-15                   --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "├─encoder_block: 1-4                     --\n",
      "|    └─conv_block: 2-7                   --\n",
      "|    |    └─Conv2d: 3-16                 295,168\n",
      "|    |    └─BatchNorm2d: 3-17            512\n",
      "|    |    └─Conv2d: 3-18                 590,080\n",
      "|    |    └─BatchNorm2d: 3-19            512\n",
      "|    |    └─ReLU: 3-20                   --\n",
      "|    └─MaxPool2d: 2-8                    --\n",
      "├─encoder_block: 1-5                     --\n",
      "|    └─conv_block: 2-9                   --\n",
      "|    |    └─Conv2d: 3-21                 1,180,160\n",
      "|    |    └─BatchNorm2d: 3-22            1,024\n",
      "|    |    └─Conv2d: 3-23                 2,359,808\n",
      "|    |    └─BatchNorm2d: 3-24            1,024\n",
      "|    |    └─ReLU: 3-25                   --\n",
      "|    └─MaxPool2d: 2-10                   --\n",
      "├─conv_block: 1-6                        --\n",
      "|    └─Conv2d: 2-11                      4,719,616\n",
      "|    └─BatchNorm2d: 2-12                 2,048\n",
      "|    └─Conv2d: 2-13                      9,438,208\n",
      "|    └─BatchNorm2d: 2-14                 2,048\n",
      "|    └─ReLU: 2-15                        --\n",
      "├─decoder_block: 1-7                     --\n",
      "|    └─ConvTranspose2d: 2-16             2,097,664\n",
      "|    └─conv_block: 2-17                  --\n",
      "|    |    └─Conv2d: 3-26                 4,719,104\n",
      "|    |    └─BatchNorm2d: 3-27            1,024\n",
      "|    |    └─Conv2d: 3-28                 2,359,808\n",
      "|    |    └─BatchNorm2d: 3-29            1,024\n",
      "|    |    └─ReLU: 3-30                   --\n",
      "├─decoder_block: 1-8                     --\n",
      "|    └─ConvTranspose2d: 2-18             524,544\n",
      "|    └─conv_block: 2-19                  --\n",
      "|    |    └─Conv2d: 3-31                 1,179,904\n",
      "|    |    └─BatchNorm2d: 3-32            512\n",
      "|    |    └─Conv2d: 3-33                 590,080\n",
      "|    |    └─BatchNorm2d: 3-34            512\n",
      "|    |    └─ReLU: 3-35                   --\n",
      "├─decoder_block: 1-9                     --\n",
      "|    └─ConvTranspose2d: 2-20             131,200\n",
      "|    └─conv_block: 2-21                  --\n",
      "|    |    └─Conv2d: 3-36                 295,040\n",
      "|    |    └─BatchNorm2d: 3-37            256\n",
      "|    |    └─Conv2d: 3-38                 147,584\n",
      "|    |    └─BatchNorm2d: 3-39            256\n",
      "|    |    └─ReLU: 3-40                   --\n",
      "├─decoder_block: 1-10                    --\n",
      "|    └─ConvTranspose2d: 2-22             32,832\n",
      "|    └─conv_block: 2-23                  --\n",
      "|    |    └─Conv2d: 3-41                 73,792\n",
      "|    |    └─BatchNorm2d: 3-42            128\n",
      "|    |    └─Conv2d: 3-43                 36,928\n",
      "|    |    └─BatchNorm2d: 3-44            128\n",
      "|    |    └─ReLU: 3-45                   --\n",
      "├─decoder_block: 1-11                    --\n",
      "|    └─ConvTranspose2d: 2-24             8,224\n",
      "|    └─conv_block: 2-25                  --\n",
      "|    |    └─Conv2d: 3-46                 18,464\n",
      "|    |    └─BatchNorm2d: 3-47            64\n",
      "|    |    └─Conv2d: 3-48                 9,248\n",
      "|    |    └─BatchNorm2d: 3-49            64\n",
      "|    |    └─ReLU: 3-50                   --\n",
      "├─Conv2d: 1-12                           396\n",
      "=================================================================\n",
      "Total params: 31,107,180\n",
      "Trainable params: 31,107,180\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─encoder_block: 1-1                     --\n",
       "|    └─conv_block: 2-1                   --\n",
       "|    |    └─Conv2d: 3-1                  1,184\n",
       "|    |    └─BatchNorm2d: 3-2             64\n",
       "|    |    └─Conv2d: 3-3                  9,248\n",
       "|    |    └─BatchNorm2d: 3-4             64\n",
       "|    |    └─ReLU: 3-5                    --\n",
       "|    └─MaxPool2d: 2-2                    --\n",
       "├─encoder_block: 1-2                     --\n",
       "|    └─conv_block: 2-3                   --\n",
       "|    |    └─Conv2d: 3-6                  18,496\n",
       "|    |    └─BatchNorm2d: 3-7             128\n",
       "|    |    └─Conv2d: 3-8                  36,928\n",
       "|    |    └─BatchNorm2d: 3-9             128\n",
       "|    |    └─ReLU: 3-10                   --\n",
       "|    └─MaxPool2d: 2-4                    --\n",
       "├─encoder_block: 1-3                     --\n",
       "|    └─conv_block: 2-5                   --\n",
       "|    |    └─Conv2d: 3-11                 73,856\n",
       "|    |    └─BatchNorm2d: 3-12            256\n",
       "|    |    └─Conv2d: 3-13                 147,584\n",
       "|    |    └─BatchNorm2d: 3-14            256\n",
       "|    |    └─ReLU: 3-15                   --\n",
       "|    └─MaxPool2d: 2-6                    --\n",
       "├─encoder_block: 1-4                     --\n",
       "|    └─conv_block: 2-7                   --\n",
       "|    |    └─Conv2d: 3-16                 295,168\n",
       "|    |    └─BatchNorm2d: 3-17            512\n",
       "|    |    └─Conv2d: 3-18                 590,080\n",
       "|    |    └─BatchNorm2d: 3-19            512\n",
       "|    |    └─ReLU: 3-20                   --\n",
       "|    └─MaxPool2d: 2-8                    --\n",
       "├─encoder_block: 1-5                     --\n",
       "|    └─conv_block: 2-9                   --\n",
       "|    |    └─Conv2d: 3-21                 1,180,160\n",
       "|    |    └─BatchNorm2d: 3-22            1,024\n",
       "|    |    └─Conv2d: 3-23                 2,359,808\n",
       "|    |    └─BatchNorm2d: 3-24            1,024\n",
       "|    |    └─ReLU: 3-25                   --\n",
       "|    └─MaxPool2d: 2-10                   --\n",
       "├─conv_block: 1-6                        --\n",
       "|    └─Conv2d: 2-11                      4,719,616\n",
       "|    └─BatchNorm2d: 2-12                 2,048\n",
       "|    └─Conv2d: 2-13                      9,438,208\n",
       "|    └─BatchNorm2d: 2-14                 2,048\n",
       "|    └─ReLU: 2-15                        --\n",
       "├─decoder_block: 1-7                     --\n",
       "|    └─ConvTranspose2d: 2-16             2,097,664\n",
       "|    └─conv_block: 2-17                  --\n",
       "|    |    └─Conv2d: 3-26                 4,719,104\n",
       "|    |    └─BatchNorm2d: 3-27            1,024\n",
       "|    |    └─Conv2d: 3-28                 2,359,808\n",
       "|    |    └─BatchNorm2d: 3-29            1,024\n",
       "|    |    └─ReLU: 3-30                   --\n",
       "├─decoder_block: 1-8                     --\n",
       "|    └─ConvTranspose2d: 2-18             524,544\n",
       "|    └─conv_block: 2-19                  --\n",
       "|    |    └─Conv2d: 3-31                 1,179,904\n",
       "|    |    └─BatchNorm2d: 3-32            512\n",
       "|    |    └─Conv2d: 3-33                 590,080\n",
       "|    |    └─BatchNorm2d: 3-34            512\n",
       "|    |    └─ReLU: 3-35                   --\n",
       "├─decoder_block: 1-9                     --\n",
       "|    └─ConvTranspose2d: 2-20             131,200\n",
       "|    └─conv_block: 2-21                  --\n",
       "|    |    └─Conv2d: 3-36                 295,040\n",
       "|    |    └─BatchNorm2d: 3-37            256\n",
       "|    |    └─Conv2d: 3-38                 147,584\n",
       "|    |    └─BatchNorm2d: 3-39            256\n",
       "|    |    └─ReLU: 3-40                   --\n",
       "├─decoder_block: 1-10                    --\n",
       "|    └─ConvTranspose2d: 2-22             32,832\n",
       "|    └─conv_block: 2-23                  --\n",
       "|    |    └─Conv2d: 3-41                 73,792\n",
       "|    |    └─BatchNorm2d: 3-42            128\n",
       "|    |    └─Conv2d: 3-43                 36,928\n",
       "|    |    └─BatchNorm2d: 3-44            128\n",
       "|    |    └─ReLU: 3-45                   --\n",
       "├─decoder_block: 1-11                    --\n",
       "|    └─ConvTranspose2d: 2-24             8,224\n",
       "|    └─conv_block: 2-25                  --\n",
       "|    |    └─Conv2d: 3-46                 18,464\n",
       "|    |    └─BatchNorm2d: 3-47            64\n",
       "|    |    └─Conv2d: 3-48                 9,248\n",
       "|    |    └─BatchNorm2d: 3-49            64\n",
       "|    |    └─ReLU: 3-50                   --\n",
       "├─Conv2d: 1-12                           396\n",
       "=================================================================\n",
       "Total params: 31,107,180\n",
       "Trainable params: 31,107,180\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print network summary\n",
    "summary(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:10<17:30, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:20<16:57, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:30<16:34, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:40<16:13, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:51<16:02, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:01<16:04, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:13<16:45, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:24<16:54, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ new batch --------------\n",
      "Input: ('images/SonyImages/Sony/short/00001_00_0.1s.ARW', 'images/SonyImages/Sony/short/00001_01_0.1s.ARW', 'images/SonyImages/Sony/short/00001_02_0.1s.ARW', 'images/SonyImages/Sony/short/00001_03_0.1s.ARW', 'images/SonyImages/Sony/short/00001_04_0.1s.ARW', 'images/SonyImages/Sony/short/00001_05_0.1s.ARW', 'images/SonyImages/Sony/short/00001_06_0.1s.ARW', 'images/SonyImages/Sony/short/00001_07_0.1s.ARW', 'images/SonyImages/Sony/short/00001_08_0.1s.ARW', 'images/SonyImages/Sony/short/00001_09_0.1s.ARW')\n",
      "Label: ('images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW', 'images/SonyImages/Sony/long/00001_00_10s.ARW')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:37<18:36, 12.14s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17304\\2242852057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;31m# backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liamr\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\liamr\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "cnt = 0\n",
    "\n",
    "# loop over epochs with tqdm progress bar\n",
    "t = trange(n_epochs, leave=True)\n",
    "for epoch in t:\n",
    "    # initialize the training and validation loss for this epoch\n",
    "    train_loss_epoch = 0.0\n",
    "    valid_loss_epoch = 0.0\n",
    "\n",
    "    # set the model to training mode\n",
    "    Net.train()\n",
    "\n",
    "\n",
    "    # loop over the training data\n",
    "    #### IMPORTANT ####\n",
    "    # len(images) == 3, if we are in the small size, so perhaps we can\n",
    "    # heuristically increase this in order to get better results\n",
    "    # sinze now it's just 3 images per epoch\n",
    "    for input, label in dataloader:\n",
    "        # load the first image and label\n",
    "        print(' ------------ new batch --------------')\n",
    "        print(\"Input: \" + str(input))\n",
    "        print(\"Label: \" + str(label))\n",
    "\n",
    "        ratio = min(10.0 / 0.1, 300)\n",
    "\n",
    "\n",
    "        input = input[0]\n",
    "        label = label[0]\n",
    "\n",
    "        exposure_input = float(((input.split('_'))[-1]).rstrip('s.ARW'))\n",
    "        exposure_label = float(((label.split('_'))[-1]).rstrip('s.ARW'))\n",
    "        ratio = min(exposure_label / exposure_label, 300)\n",
    "\n",
    "\n",
    "        #image = rawpy.imread(input)\n",
    "        image = pack_raw(rawpy.imread(input)) * ratio\n",
    "        #image = np.expand_dims(image, axis=0)\n",
    "        label = rawpy.imread(label)\n",
    "\n",
    "        # convert the image and label to numpy arrays\n",
    "        #image = image.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        label = label.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "\n",
    "        # convert the image and label to float32 data type\n",
    "        #image = np.float32(image / 65535.0)\n",
    "        label = np.float32(label / 65535.0)\n",
    "        #label = np.expand_dims(label, axis=0)\n",
    "\n",
    "        # strip input and label from paranthese\n",
    "        # if cnt % 20 == 0:\n",
    "        #     # display the image and label\n",
    "        #     # print(\"Input:\")\n",
    "        #     # plt.imshow(image)\n",
    "        #     # plt.show()\n",
    "        #     print(\"Label:\")\n",
    "        #     plt.imshow(label)\n",
    "        #     plt.show()\n",
    "\n",
    "\n",
    "        ####### POSTPROCESSING #######\n",
    "\n",
    "        # crop the image and label to 512 x 512\n",
    "        image, label = random_crop(image, label, patch_size)\n",
    "\n",
    "        # if cnt % 20 == 0:\n",
    "        #     # display the image and label\n",
    "        #     # print(\"Input patch:\")\n",
    "        #     # plt.imshow(image)\n",
    "        #     # plt.show()\n",
    "        #     print(\"Label patch:\")\n",
    "        #     plt.imshow(label)\n",
    "        #     plt.show()\n",
    "\n",
    "        # convert the image and label to tensors\n",
    "        image = torch.from_numpy(np.expand_dims(np.transpose(image, (2, 0, 1)), axis=0))\n",
    "        label = torch.from_numpy(np.expand_dims(np.transpose(label, (2, 0, 1)), axis=0))\n",
    "\n",
    "        # move the image and label to the device\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = Net(image)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        if cnt % 20 == 0:\n",
    "            # # also display the input patch\n",
    "            # # print(\"Label:\")\n",
    "            label_image = label[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "            # # plt.imshow(label_image)\n",
    "            # # plt.show()\n",
    "            # print(\"Output:\")\n",
    "            output_image = output[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "            output_image = np.minimum(np.maximum(output_image, 0), 1)\n",
    "            output_image = np.concatenate((label_image, output_image), axis=1)\n",
    "            # #output_image[:, :, [0, 1]] = output_image[:, :, [1, 0]]\n",
    "            # plt.imshow(output_image)\n",
    "            # plt.show()\n",
    "            # print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "            if not os.path.isdir(result_dir + '%04d' % epoch):\n",
    "                os.makedirs(result_dir + '%04d' % epoch)\n",
    "            functions.toimage(output_image * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
    "                result_dir + '%04d/%05d_' % (epoch, ratio) + str(os.path.basename(input)[:-3]) + 'jpg')\n",
    "\n",
    "\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print the loss\n",
    "        # print(\"==> Loss: {}\".format(loss.item()))\n",
    "        epoch_loss = loss.item()\n",
    "\n",
    "        # update the training loss\n",
    "        train_loss_epoch += loss.item()\n",
    "\n",
    "        # append loss to the list\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        cnt = cnt + 1  \n",
    "        \n",
    "\n",
    "# plot loss\n",
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in Net.state_dict():\n",
    "    print(param_tensor, \"\\t\", Net.state_dict()[param_tensor].size())\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "torch.save(Net.state_dict(), \"checkpoints/26-03-2023.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
